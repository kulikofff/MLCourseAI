{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info from https://xgboost.readthedocs.io/en/stable/tutorials/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in e:\\kulikov\\ml\\mlcourseai\\mlcourseai\\.venv\\lib\\site-packages (1.7.4)\n",
      "Requirement already satisfied: numpy in e:\\kulikov\\ml\\mlcourseai\\mlcourseai\\.venv\\lib\\site-packages (from xgboost) (1.24.2)\n",
      "Requirement already satisfied: scipy in e:\\kulikov\\ml\\mlcourseai\\mlcourseai\\.venv\\lib\\site-packages (from xgboost) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "# For my Python 3.11 venv\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. GETTING STARTED\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "# read data\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'], test_size=.2)\n",
    "# create model instance\n",
    "bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "# fit model\n",
    "bst.fit(X_train, y_train)\n",
    "# make predictions\n",
    "preds = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.9, 3.8, 6.4, 2. ],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [5.9, 3. , 5.1, 1.8],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [5.1, 3.5, 1.4, 0.2],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [7.4, 2.8, 6.1, 1.9]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Introduction to Model IO\n",
    "#Shift+Alt+F for normal view in VSC\n",
    "bst.save_model('model_file_name.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=2, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=2, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=2, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst # it is a XGBClassifier https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'multi:softprob',\n",
       " 'use_label_encoder': None,\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': 1,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': 2,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 2,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'predictor': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.get_params()\n",
    "# About these part in the next video with Python Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds-y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916666666666667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_acc = bst.score(X_train, y_train)\n",
    "model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. DART BOOSTER\n",
    "# XGBoost mostly combines a huge number of regression trees with a small learning rate. In this situation, trees added early are significant and trees added late are unimportant.\n",
    "# It's a new method to add dropout techniques from the deep neural net community to boosted trees, and reported better results in some situations.\n",
    "# Features:\n",
    "# - Drop trees in order to solve the over-fitting.\n",
    "# - Trivial trees (to correct trivial errors) may be prevented.\n",
    "\n",
    "import xgboost as xgb\n",
    "# read in data\n",
    "#d_train = xgb.DMatrix('./agaricus.txt.train#dtrain.cache')\n",
    "#d_test = xgb.DMatrix('./agaricus.txt.test#dtest.cache')\n",
    "\n",
    "#d_train = xgb.DMatrix('./agaricus.txt.train')\n",
    "#d_test = xgb.DMatrix('./agaricus.txt.test')\n",
    "\n",
    "\n",
    "# DMatrix is the basic data storage for XGBoost used by all XGBoost algorithms including both training, prediction and explanation. There are a few\n",
    "# variants of DMatrix including normal DMatrix, which is a CSR matrix, QuantileDMatrix, which is used by histogram-based tree methods for saving memory,\n",
    "# and lastly the experimental external-memory-based DMatrix, which reads data in batches during training. \n",
    "# NB! XGBoost DMatrix will blindly use the default LIBSVM parser. For CSV files, users need to provide an URI in the form of train.csv?format=csv\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, y_train)\n",
    "d_test = xgb.DMatrix(X_test, y_test)\n",
    "\n",
    "# specify parameters via map\n",
    "params = {'booster': 'dart',\n",
    "         'max_depth': 5, 'learning_rate': 0.1,\n",
    "         'num_class': 3, 'objective': 'multi:softmax', #for multicalss classification\n",
    "         'sample_type': 'uniform',\n",
    "         'normalize_type': 'tree',\n",
    "         'rate_drop': 0.1,\n",
    "         'skip_drop': 0.5}\n",
    "num_round = 50\n",
    "bst_dart = xgb.train(params, d_train, num_round)\n",
    "preds_dart = bst_dart.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0., -1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0., -1.,  0.,  0.])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Works fine:)\n",
    "preds_dart-y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x2936ea5e850>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It's a booster - https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.Booster\n",
    "bst_dart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f0': 35.0, 'f1': 29.0, 'f2': 265.0, 'f3': 93.0}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_dart.get_score() # feature importance of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Standalone Random Forest  https://xgboost.readthedocs.io/en/stable/tutorials/rf.html\n",
    "# We can use XGBoost to train a standalone random forest or use random forest as a base model for gradient boosting with the following params:\n",
    "\n",
    "params = {\n",
    "  'colsample_bynode': 0.8,\n",
    "  'learning_rate': 1,\n",
    "  'max_depth': 5,\n",
    "  'num_parallel_tree': 100,\n",
    "  'objective': 'binary:logistic',\n",
    "  'subsample': 0.8,\n",
    "  'tree_method': 'gpu_hist'\n",
    "}\n",
    "\n",
    "bst_SRF = xgb.train(params, d_train, num_boost_round=1)\n",
    "\n",
    "#It will give a mistake, because data is not binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Feature interaction constraints.\n",
    "# \n",
    "# It allows users to decide which variables are allowed to interact and which are not.\n",
    "# Potential benefits include:\n",
    "#   Better predictive performance from focusing on interactions that work – whether through domain specific knowledge or algorithms that rank interactions\n",
    "#   Less noise in predictions; better generalization\n",
    "#   More control to the user on what the model can fit. For example, the user may want to exclude some interactions even if they perform well due to regulatory constraints.\n",
    "\n",
    "# For example, the constraint [0, 1] indicates that variables X0 and X1 are allowed to interact with each other but with no other variable. \n",
    "\n",
    "params_constrained = params.copy()\n",
    "# Use nested list to define feature interaction constraints\n",
    "params_constrained['interaction_constraints'] = '[[0, 1], [2, 3]]'\n",
    "\n",
    "model_with_constraints = xgb.train(params_constrained, d_train,\n",
    "                                   num_boost_round = 1000)\n",
    "model_with_constraints.save_model('model_with_constraints.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_constr = model_with_constraints.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0., -1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0., -1.,  0.,  0.])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_constr-y_test\n",
    "#Difference appered - it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB! XGBoost’s Python package supports using feature names instead of feature index for specifying the constraints. \n",
    "# Given a data frame with columns [\"f0\", \"f1\", \"f2\"], the feature interaction constraint can be specified as [[\"f0\", \"f2\"]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Survival analysis\n",
    "\n",
    "# Survival analysis (regression) models time to an event of interest. Survival analysis is a special kind of regression and differs from the conventional regression task as follows:\n",
    "# The label is always positive, since you cannot wait a negative amount of time until the event occurs.\n",
    "# The label may not be fully known, or censored, because “it takes time to measure time.”\n",
    "# For example, it helps to works with infinity in target values\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "# 4-by-2 Data matrix\n",
    "X = np.array([[1, -1], [-1, 1], [0, 1], [1, 0]])\n",
    "SAtrain = xgb.DMatrix(X)\n",
    "\n",
    "# Associate ranged labels with the data matrix.\n",
    "# This example shows each kind of censored labels.\n",
    "#                         uncensored    right     left  interval\n",
    "y_lower_bound = np.array([      2.0,     3.0,     0.0,     4.0])\n",
    "y_upper_bound = np.array([      2.0, +np.inf,     4.0,     5.0])\n",
    "SAtrain.set_float_info('label_lower_bound', y_lower_bound)\n",
    "SAtrain.set_float_info('label_upper_bound', y_upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aft-nloglik:2.30142\n",
      "[1]\ttrain-aft-nloglik:2.24184\n",
      "[2]\ttrain-aft-nloglik:2.18633\n",
      "[3]\ttrain-aft-nloglik:2.13462\n",
      "[4]\ttrain-aft-nloglik:2.08645\n"
     ]
    }
   ],
   "source": [
    "# invoke the training API:\n",
    "# Note that it is not yet possible to set the ranged label using the scikit-learn interface (e.g. xgboost.XGBRegressor). For now, you should use xgboost.train with xgboost.DMatrix\n",
    "\n",
    "params = {'objective': 'survival:aft', # for this task\n",
    "          'eval_metric': 'aft-nloglik', # for this task\n",
    "          'aft_loss_distribution': 'normal', # for this task\n",
    "          'aft_loss_distribution_scale': 1.20, # for this task\n",
    "          'tree_method': 'hist', 'learning_rate': 0.05, 'max_depth': 2}\n",
    "bst_surv_SA = xgb.train(params, SAtrain, num_boost_round=5,\n",
    "                evals=[(SAtrain, 'train')])\n",
    "\n",
    "bst_surv_SA.save_model('bst_surv.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Customized Objective Function\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "def gradient(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
    "    '''Compute the gradient squared log error.'''\n",
    "    y = dtrain.get_label()\n",
    "    return (np.log1p(predt) - np.log1p(y)) / (predt + 1)\n",
    "\n",
    "def hessian(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
    "    '''Compute the hessian for squared log error.'''\n",
    "    y = dtrain.get_label()\n",
    "    return ((-np.log1p(predt) + np.log1p(y) + 1) /\n",
    "            np.power(predt + 1, 2))\n",
    "\n",
    "def squared_log(predt: np.ndarray,\n",
    "                dtrain: xgb.DMatrix) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    '''Squared Log Error objective. A simplified version for RMSLE used as\n",
    "    objective function.\n",
    "    '''\n",
    "    predt[predt < -1] = -1 + 1e-6\n",
    "    grad = gradient(predt, dtrain)\n",
    "    hess = hessian(predt, dtrain)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective is then used as a callback function for XGBoost during training by passing it as an argument to xgb.train\n",
    "\n",
    "xgb_def = xgb.train({'tree_method': 'hist', 'seed': 1994},  # any other tree method is fine.\n",
    "           dtrain=d_train,\n",
    "           num_boost_round=10,\n",
    "           obj=squared_log)\n",
    "\n",
    "xgb_def.save_model('xgb_def.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tdtrain-PyRMSLE:0.37276\tdtest-PyRMSLE:0.40974\n",
      "[1]\tdtrain-PyRMSLE:0.30139\tdtest-PyRMSLE:0.34202\n",
      "[2]\tdtrain-PyRMSLE:0.24429\tdtest-PyRMSLE:0.29062\n",
      "[3]\tdtrain-PyRMSLE:0.19758\tdtest-PyRMSLE:0.24313\n",
      "[4]\tdtrain-PyRMSLE:0.15996\tdtest-PyRMSLE:0.20576\n",
      "[5]\tdtrain-PyRMSLE:0.12990\tdtest-PyRMSLE:0.17592\n",
      "[6]\tdtrain-PyRMSLE:0.10622\tdtest-PyRMSLE:0.15912\n",
      "[7]\tdtrain-PyRMSLE:0.08804\tdtest-PyRMSLE:0.14321\n",
      "[8]\tdtrain-PyRMSLE:0.07397\tdtest-PyRMSLE:0.13277\n",
      "[9]\tdtrain-PyRMSLE:0.06376\tdtest-PyRMSLE:0.12323\n"
     ]
    }
   ],
   "source": [
    "# Customized Metric Function\n",
    "\n",
    "def rmsle(predt: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[str, float]:\n",
    "    ''' Root mean squared log error metric.'''\n",
    "    y = dtrain.get_label()\n",
    "    predt[predt < -1] = -1 + 1e-6\n",
    "    elements = np.power(np.log1p(y) - np.log1p(predt), 2)\n",
    "    return 'PyRMSLE', float(np.sqrt(np.sum(elements) / len(y)))\n",
    "\n",
    "\n",
    "xgb_def_metric = xgb.train({'tree_method': 'hist', 'seed': 1994,\n",
    "           'disable_default_eval_metric': 1},\n",
    "                           \n",
    "# Notice that the parameter disable_default_eval_metric is used to suppress the default metric in XGBoost.\n",
    "          dtrain=d_train,\n",
    "          num_boost_round=10,\n",
    "          obj=squared_log,\n",
    "          custom_metric=rmsle,\n",
    "# In tutorial is used feval, but it gives an error with recommendation to put custom_metric\n",
    "          evals=[(d_train, 'dtrain'), (d_test, 'dtest')],)\n",
    "#          evals_result=results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:125.60229\tvalidation_0-mean_absolute_error:107.86327\n",
      "[1]\tvalidation_0-rmse:94.53059\tvalidation_0-mean_absolute_error:78.02611\n",
      "[2]\tvalidation_0-rmse:72.70615\tvalidation_0-mean_absolute_error:57.60754\n",
      "[3]\tvalidation_0-rmse:57.41636\tvalidation_0-mean_absolute_error:44.09879\n",
      "[4]\tvalidation_0-rmse:46.72110\tvalidation_0-mean_absolute_error:35.53532\n",
      "[5]\tvalidation_0-rmse:39.40697\tvalidation_0-mean_absolute_error:30.12643\n",
      "[6]\tvalidation_0-rmse:33.75610\tvalidation_0-mean_absolute_error:25.94312\n",
      "[7]\tvalidation_0-rmse:29.48226\tvalidation_0-mean_absolute_error:22.60080\n",
      "[8]\tvalidation_0-rmse:26.30025\tvalidation_0-mean_absolute_error:20.16968\n",
      "[9]\tvalidation_0-rmse:23.10979\tvalidation_0-mean_absolute_error:17.79017\n",
      "[10]\tvalidation_0-rmse:21.35165\tvalidation_0-mean_absolute_error:16.31033\n",
      "[11]\tvalidation_0-rmse:19.53509\tvalidation_0-mean_absolute_error:14.95299\n",
      "[12]\tvalidation_0-rmse:18.42825\tvalidation_0-mean_absolute_error:14.12309\n",
      "[13]\tvalidation_0-rmse:17.15199\tvalidation_0-mean_absolute_error:13.13535\n",
      "[14]\tvalidation_0-rmse:15.62577\tvalidation_0-mean_absolute_error:11.86242\n",
      "[15]\tvalidation_0-rmse:15.10604\tvalidation_0-mean_absolute_error:11.44101\n",
      "[16]\tvalidation_0-rmse:14.26707\tvalidation_0-mean_absolute_error:10.78244\n",
      "[17]\tvalidation_0-rmse:13.26172\tvalidation_0-mean_absolute_error:9.95314\n",
      "[18]\tvalidation_0-rmse:12.79556\tvalidation_0-mean_absolute_error:9.53170\n",
      "[19]\tvalidation_0-rmse:11.83669\tvalidation_0-mean_absolute_error:8.79309\n",
      "[20]\tvalidation_0-rmse:11.68172\tvalidation_0-mean_absolute_error:8.60161\n",
      "[21]\tvalidation_0-rmse:11.11805\tvalidation_0-mean_absolute_error:8.19914\n",
      "[22]\tvalidation_0-rmse:10.69094\tvalidation_0-mean_absolute_error:7.83645\n",
      "[23]\tvalidation_0-rmse:10.13389\tvalidation_0-mean_absolute_error:7.40532\n",
      "[24]\tvalidation_0-rmse:9.45950\tvalidation_0-mean_absolute_error:6.84925\n",
      "[25]\tvalidation_0-rmse:8.81668\tvalidation_0-mean_absolute_error:6.35195\n",
      "[26]\tvalidation_0-rmse:8.38823\tvalidation_0-mean_absolute_error:6.05989\n",
      "[27]\tvalidation_0-rmse:7.87457\tvalidation_0-mean_absolute_error:5.65038\n",
      "[28]\tvalidation_0-rmse:7.58585\tvalidation_0-mean_absolute_error:5.41957\n",
      "[29]\tvalidation_0-rmse:7.12735\tvalidation_0-mean_absolute_error:5.09982\n",
      "[30]\tvalidation_0-rmse:6.77737\tvalidation_0-mean_absolute_error:4.83167\n",
      "[31]\tvalidation_0-rmse:6.52171\tvalidation_0-mean_absolute_error:4.64407\n",
      "[32]\tvalidation_0-rmse:6.15232\tvalidation_0-mean_absolute_error:4.32023\n",
      "[33]\tvalidation_0-rmse:5.78856\tvalidation_0-mean_absolute_error:4.08167\n",
      "[34]\tvalidation_0-rmse:5.73804\tvalidation_0-mean_absolute_error:4.03156\n",
      "[35]\tvalidation_0-rmse:5.52209\tvalidation_0-mean_absolute_error:3.87176\n",
      "[36]\tvalidation_0-rmse:5.28810\tvalidation_0-mean_absolute_error:3.71434\n",
      "[37]\tvalidation_0-rmse:4.86828\tvalidation_0-mean_absolute_error:3.41697\n",
      "[38]\tvalidation_0-rmse:4.56639\tvalidation_0-mean_absolute_error:3.22589\n",
      "[39]\tvalidation_0-rmse:4.33981\tvalidation_0-mean_absolute_error:3.05319\n",
      "[40]\tvalidation_0-rmse:4.00879\tvalidation_0-mean_absolute_error:2.83498\n",
      "[41]\tvalidation_0-rmse:3.79877\tvalidation_0-mean_absolute_error:2.66336\n",
      "[42]\tvalidation_0-rmse:3.69970\tvalidation_0-mean_absolute_error:2.57036\n",
      "[43]\tvalidation_0-rmse:3.62628\tvalidation_0-mean_absolute_error:2.49631\n",
      "[44]\tvalidation_0-rmse:3.35754\tvalidation_0-mean_absolute_error:2.31807\n",
      "[45]\tvalidation_0-rmse:3.27957\tvalidation_0-mean_absolute_error:2.26423\n",
      "[46]\tvalidation_0-rmse:3.21589\tvalidation_0-mean_absolute_error:2.20716\n",
      "[47]\tvalidation_0-rmse:3.17717\tvalidation_0-mean_absolute_error:2.16696\n",
      "[48]\tvalidation_0-rmse:3.00932\tvalidation_0-mean_absolute_error:2.05033\n",
      "[49]\tvalidation_0-rmse:2.88938\tvalidation_0-mean_absolute_error:1.97796\n",
      "[50]\tvalidation_0-rmse:2.80247\tvalidation_0-mean_absolute_error:1.90016\n",
      "[51]\tvalidation_0-rmse:2.66098\tvalidation_0-mean_absolute_error:1.81172\n",
      "[52]\tvalidation_0-rmse:2.39878\tvalidation_0-mean_absolute_error:1.65243\n",
      "[53]\tvalidation_0-rmse:2.22235\tvalidation_0-mean_absolute_error:1.53393\n",
      "[54]\tvalidation_0-rmse:2.11483\tvalidation_0-mean_absolute_error:1.45341\n",
      "[55]\tvalidation_0-rmse:2.01234\tvalidation_0-mean_absolute_error:1.37645\n",
      "[56]\tvalidation_0-rmse:1.88209\tvalidation_0-mean_absolute_error:1.28805\n",
      "[57]\tvalidation_0-rmse:1.85998\tvalidation_0-mean_absolute_error:1.26770\n",
      "[58]\tvalidation_0-rmse:1.68246\tvalidation_0-mean_absolute_error:1.16017\n",
      "[59]\tvalidation_0-rmse:1.58247\tvalidation_0-mean_absolute_error:1.08573\n",
      "[60]\tvalidation_0-rmse:1.49737\tvalidation_0-mean_absolute_error:1.02531\n",
      "[61]\tvalidation_0-rmse:1.42128\tvalidation_0-mean_absolute_error:0.98005\n",
      "[62]\tvalidation_0-rmse:1.35798\tvalidation_0-mean_absolute_error:0.93843\n",
      "[63]\tvalidation_0-rmse:1.32351\tvalidation_0-mean_absolute_error:0.90900\n",
      "[64]\tvalidation_0-rmse:1.24190\tvalidation_0-mean_absolute_error:0.85659\n",
      "[65]\tvalidation_0-rmse:1.23084\tvalidation_0-mean_absolute_error:0.84815\n",
      "[66]\tvalidation_0-rmse:1.17905\tvalidation_0-mean_absolute_error:0.81719\n",
      "[67]\tvalidation_0-rmse:1.12405\tvalidation_0-mean_absolute_error:0.77899\n",
      "[68]\tvalidation_0-rmse:1.11357\tvalidation_0-mean_absolute_error:0.76819\n",
      "[69]\tvalidation_0-rmse:1.08249\tvalidation_0-mean_absolute_error:0.75051\n",
      "[70]\tvalidation_0-rmse:0.99841\tvalidation_0-mean_absolute_error:0.69092\n",
      "[71]\tvalidation_0-rmse:0.94803\tvalidation_0-mean_absolute_error:0.65164\n",
      "[72]\tvalidation_0-rmse:0.92989\tvalidation_0-mean_absolute_error:0.63650\n",
      "[73]\tvalidation_0-rmse:0.90956\tvalidation_0-mean_absolute_error:0.61828\n",
      "[74]\tvalidation_0-rmse:0.89545\tvalidation_0-mean_absolute_error:0.60560\n",
      "[75]\tvalidation_0-rmse:0.87946\tvalidation_0-mean_absolute_error:0.59108\n",
      "[76]\tvalidation_0-rmse:0.81718\tvalidation_0-mean_absolute_error:0.55461\n",
      "[77]\tvalidation_0-rmse:0.75697\tvalidation_0-mean_absolute_error:0.50971\n",
      "[78]\tvalidation_0-rmse:0.70997\tvalidation_0-mean_absolute_error:0.48306\n",
      "[79]\tvalidation_0-rmse:0.69258\tvalidation_0-mean_absolute_error:0.46948\n",
      "[80]\tvalidation_0-rmse:0.65017\tvalidation_0-mean_absolute_error:0.44389\n",
      "[81]\tvalidation_0-rmse:0.60811\tvalidation_0-mean_absolute_error:0.41713\n",
      "[82]\tvalidation_0-rmse:0.59621\tvalidation_0-mean_absolute_error:0.40903\n",
      "[83]\tvalidation_0-rmse:0.56955\tvalidation_0-mean_absolute_error:0.38835\n",
      "[84]\tvalidation_0-rmse:0.53451\tvalidation_0-mean_absolute_error:0.36762\n",
      "[85]\tvalidation_0-rmse:0.51161\tvalidation_0-mean_absolute_error:0.35368\n",
      "[86]\tvalidation_0-rmse:0.48165\tvalidation_0-mean_absolute_error:0.32819\n",
      "[87]\tvalidation_0-rmse:0.45540\tvalidation_0-mean_absolute_error:0.31016\n",
      "[88]\tvalidation_0-rmse:0.44418\tvalidation_0-mean_absolute_error:0.30254\n",
      "[89]\tvalidation_0-rmse:0.43365\tvalidation_0-mean_absolute_error:0.29612\n",
      "[90]\tvalidation_0-rmse:0.40963\tvalidation_0-mean_absolute_error:0.28010\n",
      "[91]\tvalidation_0-rmse:0.38638\tvalidation_0-mean_absolute_error:0.26281\n",
      "[92]\tvalidation_0-rmse:0.37208\tvalidation_0-mean_absolute_error:0.25216\n",
      "[93]\tvalidation_0-rmse:0.36221\tvalidation_0-mean_absolute_error:0.24535\n",
      "[94]\tvalidation_0-rmse:0.33923\tvalidation_0-mean_absolute_error:0.23225\n",
      "[95]\tvalidation_0-rmse:0.33415\tvalidation_0-mean_absolute_error:0.22625\n",
      "[96]\tvalidation_0-rmse:0.31783\tvalidation_0-mean_absolute_error:0.21434\n",
      "[97]\tvalidation_0-rmse:0.30309\tvalidation_0-mean_absolute_error:0.20348\n",
      "[98]\tvalidation_0-rmse:0.29466\tvalidation_0-mean_absolute_error:0.19853\n",
      "[99]\tvalidation_0-rmse:0.28283\tvalidation_0-mean_absolute_error:0.18969\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False,\n",
       "             eval_metric=&lt;function mean_absolute_error at 0x0000029353243E20&gt;,\n",
       "             feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False,\n",
       "             eval_metric=&lt;function mean_absolute_error at 0x0000029353243E20&gt;,\n",
       "             feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False,\n",
       "             eval_metric=<function mean_absolute_error at 0x0000029353243E20>,\n",
       "             feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8. Scikit-Learn Interface - to improve the integration with standard scikit-learn functions\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "reg = xgb.XGBRegressor(\n",
    "    tree_method=\"hist\",\n",
    "    eval_metric=mean_absolute_error,\n",
    ")\n",
    "reg.fit(X, y, eval_set=[(X, y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom objective function, users can define the objective without having to access DMatrix\n",
    "\n",
    "def softprob_obj(labels: np.ndarray, predt: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    rows = labels.shape[0]\n",
    "    grad = np.zeros((rows, classes), dtype=float)\n",
    "    hess = np.zeros((rows, classes), dtype=float)\n",
    "    eps = 1e-6\n",
    "    for r in range(predt.shape[0]):\n",
    "        target = labels[r]\n",
    "        p = softmax(predt[r, :])\n",
    "        for c in range(predt.shape[1]):\n",
    "            g = p[c] - 1.0 if c == target else p[c]\n",
    "            h = max((2.0 * p[c] * (1.0 - p[c])).item(), eps)\n",
    "            grad[r, c] = g\n",
    "            hess[r, c] = h\n",
    "\n",
    "    grad = grad.reshape((rows * classes, 1))\n",
    "    hess = hess.reshape((rows * classes, 1))\n",
    "    return grad, hess\n",
    "\n",
    "clf = xgb.XGBClassifier(tree_method=\"hist\", objective=softprob_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Categorical Data - in my previous video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Multiple Outputs. For instance, a movie can be simultaneously classified as both sci-fi and comedy. \n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_multilabel_classification(\n",
    "    n_samples=32, n_classes=5, n_labels=3, random_state=0\n",
    ")\n",
    "clf = xgb.XGBClassifier(tree_method=\"hist\")\n",
    "clf.fit(X, y)\n",
    "res = np.testing.assert_allclose(clf.predict(X), y)\n",
    "# np.testing.assert_allclose: Raises an AssertionError if two objects are not equal up to desired tolerance. No error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. XGBoost forum - https://discuss.xgboost.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12. Parameter Tuning (the list of parameteres is here - https://xgboost.readthedocs.io/en/stable/python/index.html#)\n",
    "\n",
    "#12.1. Control overfitting parameters:\n",
    "    \n",
    "# - max_depth, min_child_weight and gamma.\n",
    "# - subsample and colsample_bytree.\n",
    "# - eta. Remember to increase num_round when you do so.\n",
    "\n",
    "# 2. Faster training performance\n",
    "# - tree_method, set it to hist or gpu_hist for faster computation.\n",
    "\n",
    "# 2. Handle Imbalanced Dataset (Should use in my previois video, where data is unbalanced. I used it and got an effect).\n",
    "\n",
    "# - Balance the positive and negative weights via scale_pos_weight. It is counted = sum(negative instances) / sum(positive instances).\n",
    "# - Use AUC for evaluation\n",
    "# - If you care about predicting the right probability Set parameter max_delta_step to a finite number (say 1)\n",
    "\n",
    "#12.2. \n",
    "\n",
    "# General parameters relate to which booster we are using to do boosting, commonly tree or linear model\n",
    "\n",
    "# Booster parameters depend on which booster you have chosen\n",
    "\n",
    "# Learning task parameters decide on the learning scenario. For example, regression tasks may use different parameters with ranking tasks.\n",
    "\n",
    "# Command line parameters relate to behavior of CLI version of XGBoost.\n",
    "\n",
    "# Details here - https://xgboost.readthedocs.io/en/stable/parameter.html#\n",
    "\n",
    "\n",
    "# About XGBoost Parameters, Prediction, Tree methods and Python Package will be in next video."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "288df7f25e36581787dd8e5ac5724da1da4b04fd97b34615f5cfffeb90a4c951"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
